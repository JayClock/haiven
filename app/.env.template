
# FILTER MODEL CONFIG BY CLOUD PROVIDER
ENABLED_PROVIDERS=azure,gcp,aws,ollama
ENABLED_EMBEDDINGS_MODEL=text-embedding-ada-002
ENABLED_VISION_MODEL=google-gemini

# SOURCE FOR PROMPTS AND KNOWLEDGE
# Check the documentation for the expected structure of the folder
TEAM_CONTENT_PATH=../demo-knowledge-pack
# Name of the domain to enable (subfolder name in the content path)
DOMAIN_NAME=team_demo

# OPENAI MODELS
OPENAI_API_KEY=<your API KEY>

# AZURE CHAT MODELS
AZURE_OPENAI_API_VERSION=2023-05-15
AZURE_OPENAI_API_BASE=https://tw-genai-pod-openai.openai.azure.com/
AZURE_OPENAI_API_KEY=<Azure OpenAI API Key>
AZURE_OPENAI_DEPLOYMENT_NAME_GPT4=genai-pod-experiments-gpt4-_8XPm-7dcj
AZURE_OPENAI_DEPLOYMENT_NAME_GPT35=genai-pod-experiments-gpt35-16k

# AZURE VISION MODELS
AZURE_AI_VISION_API_BASE=<Azure API Base>
AZURE_AI_VISION_API_KEY=<Azure API Key>
AZURE_AI_VISION_DEPLOYMENT_NAME="gpt-4-with-vision"
AZURE_AI_VISION_API_VERSION="2023-12-01-preview"

# AWS VISION MODELS
AWS_AI_VISION_ANTHROPIC_VERSION="bedrock-2023-05-31"
AWS_AI_VISION_MODEL_ID="anthropic.claude-3-sonnet-20240229-v1:0"

# OAUTH
OPENID_CONF_URL=<wellknown-opein-id-config-url>
OAUTH_CLIENT_ID=<oauth-client-id>
OAUTH_CLIENT_SECRET=<oauth-client-secret>

# Set to "true" at own risk - e.g. when trying out locally before OAuth is set up
# AUTH_SWITCHED_OFF=

# AWS BEDROCK AUTH
AWS_ACCESS_KEY_ID=<access-key-id>
AWS_SECRET_ACCESS_KEY=<secret-access-key>

# LOCAL
OLLAMA_BASE_URL=http://localhost:11434